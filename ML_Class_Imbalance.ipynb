{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29582ba",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb06b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compare the effect of each scaler on our dataset\n",
    "scaler = RobustScaler()\n",
    "robust_df = scaler.fit_transform(df)\n",
    "robust_df = pd.DataFrame(robust_df)\n",
    "  \n",
    "scaler = StandardScaler()\n",
    "standard_df = scaler.fit_transform(df)\n",
    "standard_df = pd.DataFrame(standard_df)\n",
    "  \n",
    "scaler = MinMaxScaler()\n",
    "minmax_df = scaler.fit_transform(df)\n",
    "minmax_df = pd.DataFrame(minmax_df)\n",
    "\n",
    "# using KDE plot\n",
    "#Note: some columns are opted out in order to speed up the process\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols = 4, figsize =(20, 5))\n",
    "ax1.set_title('Before Scaling')\n",
    "sns.kdeplot(df['XStart'], ax = ax1)\n",
    "sns.kdeplot(df['XEnd'], ax = ax1)\n",
    "sns.kdeplot(df['YStart'], ax = ax1)\n",
    "sns.kdeplot(df['YEnd'], ax = ax1)\n",
    "sns.kdeplot(df['Focal'], ax = ax1)\n",
    "sns.kdeplot(df['XSize'], ax = ax1)\n",
    "sns.kdeplot(df['YSize'], ax = ax1)\n",
    "sns.kdeplot(df['XRadius'], ax = ax1)\n",
    "sns.kdeplot(df['YRadius'], ax = ax1)\n",
    "\n",
    "ax2.set_title('After Robust Scaling')  \n",
    "sns.kdeplot(robust_df[0], ax = ax2)\n",
    "sns.kdeplot(robust_df[1], ax = ax2)\n",
    "sns.kdeplot(robust_df[2], ax = ax2)\n",
    "sns.kdeplot(robust_df[3], ax = ax2)\n",
    "sns.kdeplot(robust_df[4], ax = ax2)\n",
    "sns.kdeplot(robust_df[5], ax = ax2)\n",
    "sns.kdeplot(robust_df[6], ax = ax2)\n",
    "sns.kdeplot(robust_df[7], ax = ax2)\n",
    "sns.kdeplot(robust_df[8], ax = ax2)\n",
    "\n",
    "ax3.set_title('After Standard Scaling')  \n",
    "sns.kdeplot(standard_df[0], ax = ax3)\n",
    "sns.kdeplot(standard_df[1], ax = ax3)\n",
    "sns.kdeplot(standard_df[2], ax = ax3)\n",
    "sns.kdeplot(standard_df[3], ax = ax3)\n",
    "sns.kdeplot(standard_df[4], ax = ax3)\n",
    "sns.kdeplot(standard_df[5], ax = ax3)\n",
    "sns.kdeplot(standard_df[6], ax = ax3)\n",
    "sns.kdeplot(standard_df[7], ax = ax3)\n",
    "sns.kdeplot(standard_df[8], ax = ax3)\n",
    "\n",
    "ax4.set_title('After Min-Max Scaling')  \n",
    "sns.kdeplot(minmax_df[0], ax = ax4)\n",
    "sns.kdeplot(minmax_df[1], ax = ax4)\n",
    "sns.kdeplot(minmax_df[2], ax = ax4)\n",
    "sns.kdeplot(minmax_df[3], ax = ax4)\n",
    "sns.kdeplot(minmax_df[4], ax = ax4)\n",
    "sns.kdeplot(minmax_df[5], ax = ax4)\n",
    "sns.kdeplot(minmax_df[6], ax = ax4)\n",
    "sns.kdeplot(minmax_df[7], ax = ax4)\n",
    "sns.kdeplot(minmax_df[8], ax = ax4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Result\"]\n",
    "X = df.drop(\"Result\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "# Normalize the data\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train_normalized = scaler.fit_transform(X_train)\n",
    "#X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054c7e5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, RidgeClassifier, Perceptron, SGDClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_algorithms(Xtrain, Xtest, ytrain, ytest):\n",
    "    \n",
    "    # Create a dictionary of classification algorithms\n",
    "    algorithms = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(),\n",
    "        'Neural Network': MLPClassifier(),\n",
    "        'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "        'Extra Trees Classifier': ExtraTreesClassifier(),\n",
    "        'Bagging Classifier': BaggingClassifier(),\n",
    "        'Passive Aggressive Classifier': PassiveAggressiveClassifier(),\n",
    "        'Perceptron': Perceptron(),\n",
    "        'XGBoost Classifier': XGBClassifier(),\n",
    "        'LightGBM Classifier': LGBMClassifier()\n",
    "    }\n",
    "\n",
    "    for algorithm_name, algorithm in algorithms.items():\n",
    "        print(f\"Evaluating {algorithm_name}...\")\n",
    "        \n",
    "        # Fit the algorithm on the training data\n",
    "        algorithm.fit(Xtrain, ytrain)\n",
    "        \n",
    "        # Make predictions on the testing data\n",
    "        y_pred = algorithm.predict(Xtest)\n",
    "        \n",
    "        # Generate classification report\n",
    "        classification_report_result = classification_report(ytest, y_pred)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report_result)\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        confusion_matrix_result = confusion_matrix(ytest, y_pred)\n",
    "        \n",
    "        # Generate heatmap confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(confusion_matrix_result, fmt='.2f', annot=True, cmap='Blues')\n",
    "        plt.title(f\"{algorithm_name} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Class\")\n",
    "        plt.ylabel(\"True Class\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        print(\"----------------------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_algorithms(X_train_normalized, X_test_normalized, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb380b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad5543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9713d88a",
   "metadata": {},
   "source": [
    "# SMOTE + ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45256e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_normalized, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f850a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print('Before', counter)\n",
    "\n",
    "counter = Counter(y_train_res)\n",
    "print('After', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to demonstrate the effect of SMOTE over imbalanced datasets\n",
    "fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize =(15, 5))\n",
    "ax1.set_title('Before SMOTE')\n",
    "pd.Series(y_train).value_counts().plot.bar(ax=ax1)\n",
    "\n",
    "\n",
    "ax2.set_title('After SMOTE')  \n",
    "pd.Series(y_train_res).value_counts().plot.bar(ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61798781",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_algorithms(X_train_res, X_test_normalized, y_train_res.ravel(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4831a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407bd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727573f1",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d644b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and performance\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_weights = {0: 1, 1: 200}\n",
    "manual_weights = {0: 1, 1: 205}\n",
    "\n",
    "# Train the neural network model using the imbalanced dataset\n",
    "# Create model\n",
    "nn_model_mbalanced = Sequential()\n",
    "nn_model_mbalanced.add(Dense(2,input_dim=9,activation='relu'))\n",
    "nn_model_mbalanced.add(Dense(1,activation='sigmoid'))\n",
    "#Compile model\n",
    "nn_model_mbalanced.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "#Fit the model\n",
    "nn_model_mbalanced.fit(X_train_normalized,y_train, epochs=100, batch_size=100, class_weight=manual_weights)\n",
    "# Prediction\n",
    "nn_model_mbalanced_prediction = nn_model_mbalanced.predict(X_test_normalized)\n",
    "nn_model_mbalanced_classes = [1 if i>0.5 else 0 for i in nn_model_mbalanced_prediction]\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, nn_model_mbalanced_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00919ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "confusion_matrix_result = confusion_matrix(y_test, nn_model_mbalanced_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_result)\n",
    "        \n",
    "# Generate heatmap confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_result,fmt='.2f', annot=True, cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1f6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ffc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16159152",
   "metadata": {},
   "source": [
    "# Logistic Regression Balanced Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07246702",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/2968635393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Predicting on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "#importing and training the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='newton-cg', class_weight='balanced')\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predicting on the test data\n",
    "pred_test = lr.predict(X_test_normalized)\n",
    "\n",
    "#Calculating and printing the f1 score \n",
    "class_report_result = classification_report(y_test, pred_test)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_result)\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_matrix_result = confusion_matrix(y_test, pred_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_result)\n",
    "        \n",
    "# Generate heatmap confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_result,fmt='.2f', annot=True, cmap='Blues')\n",
    "plt.title(f\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee297e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a4396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414f440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def2b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23592cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99b678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d79c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaf0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48286e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea0430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
